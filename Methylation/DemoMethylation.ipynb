{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer learning  Based on ResNet34 for Methylation Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The network in this notebook is an implementation of the ResNet-50 [1] architecture on the CelebA face dataset [2] to train a gender classifier.  \n",
    "\n",
    "\n",
    "References\n",
    "    \n",
    "- [1] He, K., Zhang, X., Ren, S., & Sun, J. (2016). Deep residual learning for image recognition. In Proceedings of the IEEE conference on computer vision and pattern recognition (pp. 770-778). ([CVPR Link](https://www.cv-foundation.org/openaccess/content_cvpr_2016/html/He_Deep_Residual_Learning_CVPR_2016_paper.html))\n",
    "\n",
    "- [2] Zhang, K., Tan, L., Li, Z., & Qiao, Y. (2016). Gender and smile classification using deep convolutional neural networks. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition Workshops (pp. 34-38).\n",
    "\n",
    "The ResNet-50 architecture is similar to the ResNet-34 architecture shown below (from [1]):\n",
    "\n",
    "\n",
    "![](resnets/resnet34/resnet34-arch.png)\n",
    "\n",
    "However, in ResNet-50, the skip connection uses a bottleneck (from [1]):\n",
    "\n",
    "\n",
    "![](resnets/resnet50/resnet50-arch-1.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following figure illustrates residual blocks with skip connections such that the input passed via the shortcut matches the dimensions of the main path's output, which allows the network to learn identity functions.\n",
    "\n",
    "![](resnets/resnet-ex-1-1.png)\n",
    "\n",
    "\n",
    "The ResNet-34 architecture actually uses residual blocks with skip connections such that the input passed via the shortcut matches is resized to dimensions of the main path's output. Such a residual block is illustrated below:\n",
    "\n",
    "![](resnets/resnet-ex-1-2.png)\n",
    "\n",
    "The ResNet-50 uses a bottleneck as shown below:\n",
    "\n",
    "![](resnets/resnet-ex-1-3.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import PosixPath\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Hyper-paremeters\n",
    "BATCH_SIZE = 5\n",
    "NUM_EPOCHS = 10\n",
    "LEARNING_RATE = 0.0001\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "\n",
    "## Model Architecture\n",
    "NUM_CLASSES = 2\n",
    "\n",
    "DEVICE = torch.device(\"cuda: 0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset explore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Dataset Link](https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE66695)\n",
    "\n",
    "Summary\tGenome wide DNA methylation profiling of normal and breast cancer samples. The Illumina Infinium 450k Human DNA methylation Beadchip v1.1 was used to obtain DNA methylation profiles across approximately 485577 CpGs in breast cancer and normal samples. Samples included 40 normal, 80 breast cancer samples.\n",
    " \t\n",
    "Overall design\tBisulphite converted DNA from the 120 samples were hybridised to the Illumina Infinium 450k Human Methylation Beadchip v1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = PosixPath(\".\")\n",
    "dataset_path = \"GSE66695_series_matrix.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_matrix  = pd.read_table(root_dir/dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_REF</th>\n",
       "      <th>GSM1629194</th>\n",
       "      <th>GSM1629195</th>\n",
       "      <th>GSM1629196</th>\n",
       "      <th>GSM1629197</th>\n",
       "      <th>GSM1629198</th>\n",
       "      <th>GSM1629199</th>\n",
       "      <th>GSM1629200</th>\n",
       "      <th>GSM1629201</th>\n",
       "      <th>GSM1629202</th>\n",
       "      <th>...</th>\n",
       "      <th>GSM1629304</th>\n",
       "      <th>GSM1629305</th>\n",
       "      <th>GSM1629306</th>\n",
       "      <th>GSM1629307</th>\n",
       "      <th>GSM1629308</th>\n",
       "      <th>GSM1629309</th>\n",
       "      <th>GSM1629310</th>\n",
       "      <th>GSM1629311</th>\n",
       "      <th>GSM1629312</th>\n",
       "      <th>GSM1629313</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cg00000029</td>\n",
       "      <td>0.334061</td>\n",
       "      <td>0.178954</td>\n",
       "      <td>0.172730</td>\n",
       "      <td>0.183075</td>\n",
       "      <td>0.072717</td>\n",
       "      <td>0.195457</td>\n",
       "      <td>0.287615</td>\n",
       "      <td>0.339056</td>\n",
       "      <td>0.195401</td>\n",
       "      <td>...</td>\n",
       "      <td>0.171595</td>\n",
       "      <td>0.220228</td>\n",
       "      <td>0.224031</td>\n",
       "      <td>0.096429</td>\n",
       "      <td>0.226318</td>\n",
       "      <td>0.169211</td>\n",
       "      <td>0.215496</td>\n",
       "      <td>0.181659</td>\n",
       "      <td>0.424289</td>\n",
       "      <td>0.168877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cg00000108</td>\n",
       "      <td>0.935733</td>\n",
       "      <td>0.937377</td>\n",
       "      <td>0.929570</td>\n",
       "      <td>0.924546</td>\n",
       "      <td>0.922173</td>\n",
       "      <td>0.880320</td>\n",
       "      <td>0.909696</td>\n",
       "      <td>0.929620</td>\n",
       "      <td>0.903362</td>\n",
       "      <td>...</td>\n",
       "      <td>0.915011</td>\n",
       "      <td>0.909828</td>\n",
       "      <td>0.918342</td>\n",
       "      <td>0.944021</td>\n",
       "      <td>0.935265</td>\n",
       "      <td>0.929773</td>\n",
       "      <td>0.901808</td>\n",
       "      <td>0.907297</td>\n",
       "      <td>0.917796</td>\n",
       "      <td>0.932770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cg00000109</td>\n",
       "      <td>0.874611</td>\n",
       "      <td>0.738671</td>\n",
       "      <td>0.741349</td>\n",
       "      <td>0.856688</td>\n",
       "      <td>0.871578</td>\n",
       "      <td>0.686862</td>\n",
       "      <td>0.730466</td>\n",
       "      <td>0.850274</td>\n",
       "      <td>0.712961</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838718</td>\n",
       "      <td>0.772767</td>\n",
       "      <td>0.737013</td>\n",
       "      <td>0.892180</td>\n",
       "      <td>0.854146</td>\n",
       "      <td>0.688073</td>\n",
       "      <td>0.756057</td>\n",
       "      <td>0.732730</td>\n",
       "      <td>0.828793</td>\n",
       "      <td>0.879740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cg00000165</td>\n",
       "      <td>0.593666</td>\n",
       "      <td>0.251576</td>\n",
       "      <td>0.258572</td>\n",
       "      <td>0.332309</td>\n",
       "      <td>0.277692</td>\n",
       "      <td>0.161782</td>\n",
       "      <td>0.205542</td>\n",
       "      <td>0.543108</td>\n",
       "      <td>0.227433</td>\n",
       "      <td>...</td>\n",
       "      <td>0.202314</td>\n",
       "      <td>0.249808</td>\n",
       "      <td>0.230911</td>\n",
       "      <td>0.136585</td>\n",
       "      <td>0.380056</td>\n",
       "      <td>0.237408</td>\n",
       "      <td>0.229581</td>\n",
       "      <td>0.246965</td>\n",
       "      <td>0.178193</td>\n",
       "      <td>0.655175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cg00000236</td>\n",
       "      <td>0.864638</td>\n",
       "      <td>0.820130</td>\n",
       "      <td>0.800612</td>\n",
       "      <td>0.884483</td>\n",
       "      <td>0.862696</td>\n",
       "      <td>0.802741</td>\n",
       "      <td>0.793261</td>\n",
       "      <td>0.838466</td>\n",
       "      <td>0.798712</td>\n",
       "      <td>...</td>\n",
       "      <td>0.891121</td>\n",
       "      <td>0.793986</td>\n",
       "      <td>0.839779</td>\n",
       "      <td>0.868582</td>\n",
       "      <td>0.857674</td>\n",
       "      <td>0.830082</td>\n",
       "      <td>0.802358</td>\n",
       "      <td>0.801136</td>\n",
       "      <td>0.888044</td>\n",
       "      <td>0.861329</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 121 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ID_REF  GSM1629194  GSM1629195  GSM1629196  GSM1629197  GSM1629198  \\\n",
       "0  cg00000029    0.334061    0.178954    0.172730    0.183075    0.072717   \n",
       "1  cg00000108    0.935733    0.937377    0.929570    0.924546    0.922173   \n",
       "2  cg00000109    0.874611    0.738671    0.741349    0.856688    0.871578   \n",
       "3  cg00000165    0.593666    0.251576    0.258572    0.332309    0.277692   \n",
       "4  cg00000236    0.864638    0.820130    0.800612    0.884483    0.862696   \n",
       "\n",
       "   GSM1629199  GSM1629200  GSM1629201  GSM1629202     ...      GSM1629304  \\\n",
       "0    0.195457    0.287615    0.339056    0.195401     ...        0.171595   \n",
       "1    0.880320    0.909696    0.929620    0.903362     ...        0.915011   \n",
       "2    0.686862    0.730466    0.850274    0.712961     ...        0.838718   \n",
       "3    0.161782    0.205542    0.543108    0.227433     ...        0.202314   \n",
       "4    0.802741    0.793261    0.838466    0.798712     ...        0.891121   \n",
       "\n",
       "   GSM1629305  GSM1629306  GSM1629307  GSM1629308  GSM1629309  GSM1629310  \\\n",
       "0    0.220228    0.224031    0.096429    0.226318    0.169211    0.215496   \n",
       "1    0.909828    0.918342    0.944021    0.935265    0.929773    0.901808   \n",
       "2    0.772767    0.737013    0.892180    0.854146    0.688073    0.756057   \n",
       "3    0.249808    0.230911    0.136585    0.380056    0.237408    0.229581   \n",
       "4    0.793986    0.839779    0.868582    0.857674    0.830082    0.802358   \n",
       "\n",
       "   GSM1629311  GSM1629312  GSM1629313  \n",
       "0    0.181659    0.424289    0.168877  \n",
       "1    0.907297    0.917796    0.932770  \n",
       "2    0.732730    0.828793    0.879740  \n",
       "3    0.246965    0.178193    0.655175  \n",
       "4    0.801136    0.888044    0.861329  \n",
       "\n",
       "[5 rows x 121 columns]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_matrix.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(485578, 121)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_matrix.drop(\"ID_REF\", inplace=True, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_names = \"GSM1629194 GSM1629195 GSM1629196 GSM1629197 GSM1629198 GSM1629199 GSM1629200 GSM1629201 GSM1629202 GSM1629203 GSM1629204 GSM1629205 GSM1629206 GSM1629207 GSM1629208 GSM1629209 GSM1629210 GSM1629211 GSM1629212 GSM1629213 GSM1629214 GSM1629215 GSM1629216 GSM1629217 GSM1629218 GSM1629219 GSM1629220 GSM1629221 GSM1629222 GSM1629223 GSM1629224 GSM1629225 GSM1629226 GSM1629227 GSM1629228 GSM1629229 GSM1629230 GSM1629231 GSM1629232 GSM1629233 GSM1629234 GSM1629235 GSM1629236 GSM1629237 GSM1629238 GSM1629239 GSM1629240 GSM1629241 GSM1629242 GSM1629243 GSM1629244 GSM1629245 GSM1629246 GSM1629247 GSM1629248 GSM1629249 GSM1629250 GSM1629251 GSM1629252 GSM1629253 GSM1629254 GSM1629255 GSM1629256 GSM1629257 GSM1629258 GSM1629259 GSM1629260 GSM1629261 GSM1629262 GSM1629263 GSM1629264 GSM1629265 GSM1629266 GSM1629267 GSM1629268 GSM1629269 GSM1629270 GSM1629271 GSM1629272 GSM1629273 GSM1629274 GSM1629275 GSM1629276 GSM1629277 GSM1629278 GSM1629279 GSM1629280 GSM1629281 GSM1629282 GSM1629283 GSM1629284 GSM1629285 GSM1629286 GSM1629287 GSM1629288 GSM1629289 GSM1629290 GSM1629291 GSM1629292 GSM1629293 GSM1629294 GSM1629295 GSM1629296 GSM1629297 GSM1629298 GSM1629299 GSM1629300 GSM1629301 GSM1629302 GSM1629303 GSM1629304 GSM1629305 GSM1629306 GSM1629307 GSM1629308 GSM1629309 GSM1629310 GSM1629311 GSM1629312 GSM1629313\"\n",
    "sample_title = \"01-208-T  01-254-N  01-212-N  01-254-T  01-212-T  01-265-N  01-237-N  01-265-T  01-242-N  01-302-N  01-242-T  01-302-T  00-105-T  00-395-T  00-135-T  00-409-T  00-151-T  00-401-T  00-172-T  00-480-T  00-185-T  00-522-T  00-225-T  00-529-T  00-530-T  00-462-N  00-525-N  00-525-T  99-029-T  99-301-T  99-066-T  00-200-T  99-165-T  00-292-T  99-188-T  00-301-T  99-225-T  01-201-T  99-260-T  01-218-T  01-219-T  01-367-T  01-262-T  99-066-N  01-273-T  01-255-N  01-276-T  01-367-N  01-280-T  01-298-N  01-340-T  01-298-T  00-218-T  BS66770-N 00-291-N  BS66755-N 00-291-T  BS66498-N 01-060-T  BS66689-N 00-012-N  BS66172-N 00-012-T  BS66352-N 67777-N   67763-T   BS66770-T 67777-T   BS66352-T BS66755-T BS66689-T BS66459-T 00-144-N  00-391-T  00-164-N  01-015-N  00-218-N  01-015-T  01-123-T  01-045-T  00-359-T  01-061-N  00-360-T  01-061-T  01-066-T  01-168-T  01-116-T  01-169-T  01-144-N  01-177-N  01-144-T  01-177-T  01-148-T  01-186-N  01-168-N  01-186-T  01-199-N  99-273-N  01-199-T  99-312-T  99-013-T  99-312-T-2    99-073-T  99-344-T  99-217-N  99-359-N  99-217-T  99-369-N  99-387-T  99-506-T  99-388-T  99-523-N  99-403-N  99-523-T  99-403-T  99-536-N  99-468-N  01-083-N  99-468-T  01-083-T\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_dict = {sample: label for sample, label in zip(sample_names.split(), sample_title.split())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'GSM1629194': '01-208-T',\n",
       " 'GSM1629195': '01-254-N',\n",
       " 'GSM1629196': '01-212-N',\n",
       " 'GSM1629197': '01-254-T',\n",
       " 'GSM1629198': '01-212-T',\n",
       " 'GSM1629199': '01-265-N',\n",
       " 'GSM1629200': '01-237-N',\n",
       " 'GSM1629201': '01-265-T',\n",
       " 'GSM1629202': '01-242-N',\n",
       " 'GSM1629203': '01-302-N',\n",
       " 'GSM1629204': '01-242-T',\n",
       " 'GSM1629205': '01-302-T',\n",
       " 'GSM1629206': '00-105-T',\n",
       " 'GSM1629207': '00-395-T',\n",
       " 'GSM1629208': '00-135-T',\n",
       " 'GSM1629209': '00-409-T',\n",
       " 'GSM1629210': '00-151-T',\n",
       " 'GSM1629211': '00-401-T',\n",
       " 'GSM1629212': '00-172-T',\n",
       " 'GSM1629213': '00-480-T',\n",
       " 'GSM1629214': '00-185-T',\n",
       " 'GSM1629215': '00-522-T',\n",
       " 'GSM1629216': '00-225-T',\n",
       " 'GSM1629217': '00-529-T',\n",
       " 'GSM1629218': '00-530-T',\n",
       " 'GSM1629219': '00-462-N',\n",
       " 'GSM1629220': '00-525-N',\n",
       " 'GSM1629221': '00-525-T',\n",
       " 'GSM1629222': '99-029-T',\n",
       " 'GSM1629223': '99-301-T',\n",
       " 'GSM1629224': '99-066-T',\n",
       " 'GSM1629225': '00-200-T',\n",
       " 'GSM1629226': '99-165-T',\n",
       " 'GSM1629227': '00-292-T',\n",
       " 'GSM1629228': '99-188-T',\n",
       " 'GSM1629229': '00-301-T',\n",
       " 'GSM1629230': '99-225-T',\n",
       " 'GSM1629231': '01-201-T',\n",
       " 'GSM1629232': '99-260-T',\n",
       " 'GSM1629233': '01-218-T',\n",
       " 'GSM1629234': '01-219-T',\n",
       " 'GSM1629235': '01-367-T',\n",
       " 'GSM1629236': '01-262-T',\n",
       " 'GSM1629237': '99-066-N',\n",
       " 'GSM1629238': '01-273-T',\n",
       " 'GSM1629239': '01-255-N',\n",
       " 'GSM1629240': '01-276-T',\n",
       " 'GSM1629241': '01-367-N',\n",
       " 'GSM1629242': '01-280-T',\n",
       " 'GSM1629243': '01-298-N',\n",
       " 'GSM1629244': '01-340-T',\n",
       " 'GSM1629245': '01-298-T',\n",
       " 'GSM1629246': '00-218-T',\n",
       " 'GSM1629247': 'BS66770-N',\n",
       " 'GSM1629248': '00-291-N',\n",
       " 'GSM1629249': 'BS66755-N',\n",
       " 'GSM1629250': '00-291-T',\n",
       " 'GSM1629251': 'BS66498-N',\n",
       " 'GSM1629252': '01-060-T',\n",
       " 'GSM1629253': 'BS66689-N',\n",
       " 'GSM1629254': '00-012-N',\n",
       " 'GSM1629255': 'BS66172-N',\n",
       " 'GSM1629256': '00-012-T',\n",
       " 'GSM1629257': 'BS66352-N',\n",
       " 'GSM1629258': '67777-N',\n",
       " 'GSM1629259': '67763-T',\n",
       " 'GSM1629260': 'BS66770-T',\n",
       " 'GSM1629261': '67777-T',\n",
       " 'GSM1629262': 'BS66352-T',\n",
       " 'GSM1629263': 'BS66755-T',\n",
       " 'GSM1629264': 'BS66689-T',\n",
       " 'GSM1629265': 'BS66459-T',\n",
       " 'GSM1629266': '00-144-N',\n",
       " 'GSM1629267': '00-391-T',\n",
       " 'GSM1629268': '00-164-N',\n",
       " 'GSM1629269': '01-015-N',\n",
       " 'GSM1629270': '00-218-N',\n",
       " 'GSM1629271': '01-015-T',\n",
       " 'GSM1629272': '01-123-T',\n",
       " 'GSM1629273': '01-045-T',\n",
       " 'GSM1629274': '00-359-T',\n",
       " 'GSM1629275': '01-061-N',\n",
       " 'GSM1629276': '00-360-T',\n",
       " 'GSM1629277': '01-061-T',\n",
       " 'GSM1629278': '01-066-T',\n",
       " 'GSM1629279': '01-168-T',\n",
       " 'GSM1629280': '01-116-T',\n",
       " 'GSM1629281': '01-169-T',\n",
       " 'GSM1629282': '01-144-N',\n",
       " 'GSM1629283': '01-177-N',\n",
       " 'GSM1629284': '01-144-T',\n",
       " 'GSM1629285': '01-177-T',\n",
       " 'GSM1629286': '01-148-T',\n",
       " 'GSM1629287': '01-186-N',\n",
       " 'GSM1629288': '01-168-N',\n",
       " 'GSM1629289': '01-186-T',\n",
       " 'GSM1629290': '01-199-N',\n",
       " 'GSM1629291': '99-273-N',\n",
       " 'GSM1629292': '01-199-T',\n",
       " 'GSM1629293': '99-312-T',\n",
       " 'GSM1629294': '99-013-T',\n",
       " 'GSM1629295': '99-312-T-2',\n",
       " 'GSM1629296': '99-073-T',\n",
       " 'GSM1629297': '99-344-T',\n",
       " 'GSM1629298': '99-217-N',\n",
       " 'GSM1629299': '99-359-N',\n",
       " 'GSM1629300': '99-217-T',\n",
       " 'GSM1629301': '99-369-N',\n",
       " 'GSM1629302': '99-387-T',\n",
       " 'GSM1629303': '99-506-T',\n",
       " 'GSM1629304': '99-388-T',\n",
       " 'GSM1629305': '99-523-N',\n",
       " 'GSM1629306': '99-403-N',\n",
       " 'GSM1629307': '99-523-T',\n",
       " 'GSM1629308': '99-403-T',\n",
       " 'GSM1629309': '99-536-N',\n",
       " 'GSM1629310': '99-468-N',\n",
       " 'GSM1629311': '01-083-N',\n",
       " 'GSM1629312': '99-468-T',\n",
       " 'GSM1629313': '01-083-T'}"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_matrix.dropna(axis = 0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(408288, 120)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([408288])"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.from_numpy(data_matrix.iloc[:,1].values).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_target(target):\n",
    "    if target.split(\"-\")[-1] == \"N\":\n",
    "        return 0\n",
    "    else:\n",
    "        return 1   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_dict = {target : transform_target(target_dict[target]) for target in target_dict}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.9357331 , 0.8746111 , 0.593666  , ..., 0.9518182 , 0.9392812 ,\n",
       "       0.04467725])"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_matrix.iloc[:,0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GSEDataset(Dataset):\n",
    "    def __init__(self, data_matrix, target_dict):\n",
    "        self.data_matrix = data_matrix\n",
    "        self.target_dict = target_dict\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.target_dict)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        x = torch.from_numpy(self.data_matrix.iloc[:,idx].values).float()\n",
    "        y = torch.tensor(self.target_dict[self.data_matrix.columns[idx]])\n",
    "        return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "ges_dataset =  GSEDataset(data_matrix, target_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.8 * len(ges_dataset))\n",
    "test_size = len(ges_dataset) - train_size\n",
    "\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(ges_dataset, [train_size, test_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(dataset = train_dataset,\n",
    "                             batch_size=BATCH_SIZE,\n",
    "                             shuffle=True,\n",
    "                             num_workers=4)\n",
    "\n",
    "test_dataloader = DataLoader(dataset = test_dataset,\n",
    "                             batch_size=BATCH_SIZE,\n",
    "                             shuffle=False,\n",
    "                             num_workers=4)\n",
    "\n",
    "dataset_loader = {\"train\": train_dataloader, \"test\": test_dataloader}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "resnet = torchvision.models.resnet34(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (4): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (5): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1\n",
      "bn1\n",
      "relu\n",
      "maxpool\n",
      "layer1\n",
      "layer2\n",
      "layer3\n",
      "layer4\n",
      "avgpool\n",
      "fc\n"
     ]
    }
   ],
   "source": [
    "for name, m in resnet.named_children():\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = next(iter(dataset_loader[\"train\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 408288]), torch.Size([5]))"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.size(), y.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 2, 2, 2, 2, 3, 4253]"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def div_prime(num):\n",
    "    res = []\n",
    "    while num != 1:\n",
    "        for i in range(2, int(num+1)):\n",
    "            if num % i == 0:\n",
    "                res.append(i)\n",
    "                num = num // i\n",
    "                break\n",
    " \n",
    "    return res\n",
    "div_prime(408288)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GESMODEL(torch.nn.Module):\n",
    "    def __init__(self, num_class = NUM_CLASSES):\n",
    "        super(GESMODEL, self).__init__()\n",
    "        \n",
    "        self.adaptive_pool = torch.nn.AdaptiveAvgPool2d((224,224))\n",
    "        self.resenet = torchvision.models.resnet34(pretrained=True)\n",
    "        \n",
    "#         for param in self.resenet.parameters():\n",
    "#             param.requires_grad = False\n",
    "        \n",
    "        \n",
    "        self.resenet.fc = nn.Linear(self.resenet.fc.in_features,NUM_CLASSES)\n",
    "        torch.nn.init.normal_(self.resenet.fc.weight, 0, 0.01)\n",
    "        torch.nn.init.constant_(self.resenet.fc.bias, 0)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 3,32,4253)\n",
    "        x = self.adaptive_pool(x)\n",
    "        logits = self.resenet(x)\n",
    "        probas = F.softmax(logits, dim = 1)\n",
    "        return logits,probas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GESMODEL().to(DEVICE)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      " AdaptiveAvgPool2d-1          [-1, 3, 224, 224]               0\n",
      "            Conv2d-2         [-1, 64, 112, 112]           9,408\n",
      "       BatchNorm2d-3         [-1, 64, 112, 112]             128\n",
      "              ReLU-4         [-1, 64, 112, 112]               0\n",
      "         MaxPool2d-5           [-1, 64, 56, 56]               0\n",
      "            Conv2d-6           [-1, 64, 56, 56]          36,864\n",
      "       BatchNorm2d-7           [-1, 64, 56, 56]             128\n",
      "              ReLU-8           [-1, 64, 56, 56]               0\n",
      "            Conv2d-9           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-10           [-1, 64, 56, 56]             128\n",
      "             ReLU-11           [-1, 64, 56, 56]               0\n",
      "       BasicBlock-12           [-1, 64, 56, 56]               0\n",
      "           Conv2d-13           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-14           [-1, 64, 56, 56]             128\n",
      "             ReLU-15           [-1, 64, 56, 56]               0\n",
      "           Conv2d-16           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-17           [-1, 64, 56, 56]             128\n",
      "             ReLU-18           [-1, 64, 56, 56]               0\n",
      "       BasicBlock-19           [-1, 64, 56, 56]               0\n",
      "           Conv2d-20           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-21           [-1, 64, 56, 56]             128\n",
      "             ReLU-22           [-1, 64, 56, 56]               0\n",
      "           Conv2d-23           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-24           [-1, 64, 56, 56]             128\n",
      "             ReLU-25           [-1, 64, 56, 56]               0\n",
      "       BasicBlock-26           [-1, 64, 56, 56]               0\n",
      "           Conv2d-27          [-1, 128, 28, 28]          73,728\n",
      "      BatchNorm2d-28          [-1, 128, 28, 28]             256\n",
      "             ReLU-29          [-1, 128, 28, 28]               0\n",
      "           Conv2d-30          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-31          [-1, 128, 28, 28]             256\n",
      "           Conv2d-32          [-1, 128, 28, 28]           8,192\n",
      "      BatchNorm2d-33          [-1, 128, 28, 28]             256\n",
      "             ReLU-34          [-1, 128, 28, 28]               0\n",
      "       BasicBlock-35          [-1, 128, 28, 28]               0\n",
      "           Conv2d-36          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-37          [-1, 128, 28, 28]             256\n",
      "             ReLU-38          [-1, 128, 28, 28]               0\n",
      "           Conv2d-39          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-40          [-1, 128, 28, 28]             256\n",
      "             ReLU-41          [-1, 128, 28, 28]               0\n",
      "       BasicBlock-42          [-1, 128, 28, 28]               0\n",
      "           Conv2d-43          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-44          [-1, 128, 28, 28]             256\n",
      "             ReLU-45          [-1, 128, 28, 28]               0\n",
      "           Conv2d-46          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-47          [-1, 128, 28, 28]             256\n",
      "             ReLU-48          [-1, 128, 28, 28]               0\n",
      "       BasicBlock-49          [-1, 128, 28, 28]               0\n",
      "           Conv2d-50          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-51          [-1, 128, 28, 28]             256\n",
      "             ReLU-52          [-1, 128, 28, 28]               0\n",
      "           Conv2d-53          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-54          [-1, 128, 28, 28]             256\n",
      "             ReLU-55          [-1, 128, 28, 28]               0\n",
      "       BasicBlock-56          [-1, 128, 28, 28]               0\n",
      "           Conv2d-57          [-1, 256, 14, 14]         294,912\n",
      "      BatchNorm2d-58          [-1, 256, 14, 14]             512\n",
      "             ReLU-59          [-1, 256, 14, 14]               0\n",
      "           Conv2d-60          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-61          [-1, 256, 14, 14]             512\n",
      "           Conv2d-62          [-1, 256, 14, 14]          32,768\n",
      "      BatchNorm2d-63          [-1, 256, 14, 14]             512\n",
      "             ReLU-64          [-1, 256, 14, 14]               0\n",
      "       BasicBlock-65          [-1, 256, 14, 14]               0\n",
      "           Conv2d-66          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-67          [-1, 256, 14, 14]             512\n",
      "             ReLU-68          [-1, 256, 14, 14]               0\n",
      "           Conv2d-69          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-70          [-1, 256, 14, 14]             512\n",
      "             ReLU-71          [-1, 256, 14, 14]               0\n",
      "       BasicBlock-72          [-1, 256, 14, 14]               0\n",
      "           Conv2d-73          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-74          [-1, 256, 14, 14]             512\n",
      "             ReLU-75          [-1, 256, 14, 14]               0\n",
      "           Conv2d-76          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-77          [-1, 256, 14, 14]             512\n",
      "             ReLU-78          [-1, 256, 14, 14]               0\n",
      "       BasicBlock-79          [-1, 256, 14, 14]               0\n",
      "           Conv2d-80          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-81          [-1, 256, 14, 14]             512\n",
      "             ReLU-82          [-1, 256, 14, 14]               0\n",
      "           Conv2d-83          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-84          [-1, 256, 14, 14]             512\n",
      "             ReLU-85          [-1, 256, 14, 14]               0\n",
      "       BasicBlock-86          [-1, 256, 14, 14]               0\n",
      "           Conv2d-87          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-88          [-1, 256, 14, 14]             512\n",
      "             ReLU-89          [-1, 256, 14, 14]               0\n",
      "           Conv2d-90          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-91          [-1, 256, 14, 14]             512\n",
      "             ReLU-92          [-1, 256, 14, 14]               0\n",
      "       BasicBlock-93          [-1, 256, 14, 14]               0\n",
      "           Conv2d-94          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-95          [-1, 256, 14, 14]             512\n",
      "             ReLU-96          [-1, 256, 14, 14]               0\n",
      "           Conv2d-97          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-98          [-1, 256, 14, 14]             512\n",
      "             ReLU-99          [-1, 256, 14, 14]               0\n",
      "      BasicBlock-100          [-1, 256, 14, 14]               0\n",
      "          Conv2d-101            [-1, 512, 7, 7]       1,179,648\n",
      "     BatchNorm2d-102            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-103            [-1, 512, 7, 7]               0\n",
      "          Conv2d-104            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-105            [-1, 512, 7, 7]           1,024\n",
      "          Conv2d-106            [-1, 512, 7, 7]         131,072\n",
      "     BatchNorm2d-107            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-108            [-1, 512, 7, 7]               0\n",
      "      BasicBlock-109            [-1, 512, 7, 7]               0\n",
      "          Conv2d-110            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-111            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-112            [-1, 512, 7, 7]               0\n",
      "          Conv2d-113            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-114            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-115            [-1, 512, 7, 7]               0\n",
      "      BasicBlock-116            [-1, 512, 7, 7]               0\n",
      "          Conv2d-117            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-118            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-119            [-1, 512, 7, 7]               0\n",
      "          Conv2d-120            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-121            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-122            [-1, 512, 7, 7]               0\n",
      "      BasicBlock-123            [-1, 512, 7, 7]               0\n",
      "AdaptiveAvgPool2d-124            [-1, 512, 1, 1]               0\n",
      "          Linear-125                    [-1, 2]           1,026\n",
      "          ResNet-126                    [-1, 2]               0\n",
      "================================================================\n",
      "Total params: 21,285,698\n",
      "Trainable params: 21,285,698\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 1.56\n",
      "Forward/backward pass size (MB): 97.43\n",
      "Params size (MB): 81.20\n",
      "Estimated Total Size (MB): 180.19\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(model, (408288,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(model, data_loader, device):\n",
    "    model.eval()\n",
    "    correct_pred, num_examples = 0, 0\n",
    "    for i, (features, targets) in enumerate(data_loader):\n",
    "            \n",
    "        features = features.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        logits, probas = model(features)\n",
    "        _, predicted_labels = torch.max(probas, 1)\n",
    "        num_examples += targets.size(0)\n",
    "        correct_pred += (predicted_labels == targets).sum()\n",
    "    return correct_pred.float()/num_examples * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, data_loader, optimizer, num_epochs,batch_size, device,metric_func, random_seed = 7):\n",
    "    # Manual seed for deterministic data loader\n",
    "    torch.manual_seed(random_seed)\n",
    "    \n",
    "    loss_list = []\n",
    "    train_acc_list, valid_acc_list = [], []\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        start = time.time()\n",
    "        # set training mode\n",
    "        model.train() \n",
    "        for batch_idx, (features, targets) in enumerate(data_loader[\"train\"]):\n",
    "            features = features.to(device)\n",
    "            targets = targets.to(device)\n",
    "\n",
    "\n",
    "            ## forward pass\n",
    "            logits, probas = model(features)\n",
    "            loss = F.cross_entropy(logits,targets)\n",
    "\n",
    "            # backward pass\n",
    "            # clear the gradients of all tensors being optimized\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            ### Login\n",
    "            loss_list.append(loss.item())\n",
    "\n",
    "            print ('Epoch: {0:03d}/{1:03d} | Batch {2:03d}/{3:03d} | Loss: {4:.2f}'.format(\n",
    "                epoch+1, num_epochs, batch_idx, \n",
    "                     len(train_dataset)//batch_size, loss))\n",
    "        \n",
    "        end = time.time()\n",
    "        with torch.set_grad_enabled(False):\n",
    "            train_acc = metric_func(model, data_loader[\"train\"], device)\n",
    "            valid_acc = metric_func(model, data_loader[\"test\"], device)\n",
    "            \n",
    "            print('Epoch: {0:03d}/{1:03d} train acc: {2:.3f} % | val acc: {3:.3f} % | time: {4:.3f} s'.format(\n",
    "                  epoch+1, num_epochs, train_acc, valid_acc, end-start))\n",
    "            \n",
    "\n",
    "            \n",
    "            train_acc_list.append(train_acc)\n",
    "            valid_acc_list.append(valid_acc)\n",
    "            \n",
    "    return model, loss_list, train_acc_list, valid_acc_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001/010 | Batch 000/019 | Loss: 0.71\n",
      "Epoch: 001/010 | Batch 001/019 | Loss: 0.67\n",
      "Epoch: 001/010 | Batch 002/019 | Loss: 0.55\n",
      "Epoch: 001/010 | Batch 003/019 | Loss: 0.34\n",
      "Epoch: 001/010 | Batch 004/019 | Loss: 0.64\n",
      "Epoch: 001/010 | Batch 005/019 | Loss: 0.28\n",
      "Epoch: 001/010 | Batch 006/019 | Loss: 0.26\n",
      "Epoch: 001/010 | Batch 007/019 | Loss: 0.68\n",
      "Epoch: 001/010 | Batch 008/019 | Loss: 0.50\n",
      "Epoch: 001/010 | Batch 009/019 | Loss: 0.21\n",
      "Epoch: 001/010 | Batch 010/019 | Loss: 0.11\n",
      "Epoch: 001/010 | Batch 011/019 | Loss: 0.16\n",
      "Epoch: 001/010 | Batch 012/019 | Loss: 0.42\n",
      "Epoch: 001/010 | Batch 013/019 | Loss: 0.56\n",
      "Epoch: 001/010 | Batch 014/019 | Loss: 0.44\n",
      "Epoch: 001/010 | Batch 015/019 | Loss: 0.10\n",
      "Epoch: 001/010 | Batch 016/019 | Loss: 0.16\n",
      "Epoch: 001/010 | Batch 017/019 | Loss: 0.21\n",
      "Epoch: 001/010 | Batch 018/019 | Loss: 0.07\n",
      "Epoch: 001/010 | Batch 019/019 | Loss: 0.30\n",
      "Epoch: 001/010 train acc: 65.625 % | val acc: 70.833 % | time: 2.762 s\n",
      "Epoch: 002/010 | Batch 000/019 | Loss: 0.37\n",
      "Epoch: 002/010 | Batch 001/019 | Loss: 0.40\n",
      "Epoch: 002/010 | Batch 002/019 | Loss: 0.12\n",
      "Epoch: 002/010 | Batch 003/019 | Loss: 0.07\n",
      "Epoch: 002/010 | Batch 004/019 | Loss: 0.07\n",
      "Epoch: 002/010 | Batch 005/019 | Loss: 0.06\n",
      "Epoch: 002/010 | Batch 006/019 | Loss: 0.03\n",
      "Epoch: 002/010 | Batch 007/019 | Loss: 0.06\n",
      "Epoch: 002/010 | Batch 008/019 | Loss: 0.03\n",
      "Epoch: 002/010 | Batch 009/019 | Loss: 0.03\n",
      "Epoch: 002/010 | Batch 010/019 | Loss: 0.05\n",
      "Epoch: 002/010 | Batch 011/019 | Loss: 0.04\n",
      "Epoch: 002/010 | Batch 012/019 | Loss: 0.39\n",
      "Epoch: 002/010 | Batch 013/019 | Loss: 0.11\n",
      "Epoch: 002/010 | Batch 014/019 | Loss: 0.03\n",
      "Epoch: 002/010 | Batch 015/019 | Loss: 0.11\n",
      "Epoch: 002/010 | Batch 016/019 | Loss: 0.02\n",
      "Epoch: 002/010 | Batch 017/019 | Loss: 0.03\n",
      "Epoch: 002/010 | Batch 018/019 | Loss: 0.15\n",
      "Epoch: 002/010 | Batch 019/019 | Loss: 0.16\n",
      "Epoch: 002/010 train acc: 65.625 % | val acc: 70.833 % | time: 2.663 s\n",
      "Epoch: 003/010 | Batch 000/019 | Loss: 0.05\n",
      "Epoch: 003/010 | Batch 001/019 | Loss: 0.54\n",
      "Epoch: 003/010 | Batch 002/019 | Loss: 0.53\n",
      "Epoch: 003/010 | Batch 003/019 | Loss: 0.01\n",
      "Epoch: 003/010 | Batch 004/019 | Loss: 0.09\n",
      "Epoch: 003/010 | Batch 005/019 | Loss: 0.08\n",
      "Epoch: 003/010 | Batch 006/019 | Loss: 0.10\n",
      "Epoch: 003/010 | Batch 007/019 | Loss: 0.15\n",
      "Epoch: 003/010 | Batch 008/019 | Loss: 0.08\n",
      "Epoch: 003/010 | Batch 009/019 | Loss: 0.06\n",
      "Epoch: 003/010 | Batch 010/019 | Loss: 0.02\n",
      "Epoch: 003/010 | Batch 011/019 | Loss: 0.03\n",
      "Epoch: 003/010 | Batch 012/019 | Loss: 0.36\n",
      "Epoch: 003/010 | Batch 013/019 | Loss: 0.06\n",
      "Epoch: 003/010 | Batch 014/019 | Loss: 0.12\n",
      "Epoch: 003/010 | Batch 015/019 | Loss: 0.02\n",
      "Epoch: 003/010 | Batch 016/019 | Loss: 0.07\n",
      "Epoch: 003/010 | Batch 017/019 | Loss: 0.03\n",
      "Epoch: 003/010 | Batch 018/019 | Loss: 0.02\n",
      "Epoch: 003/010 | Batch 019/019 | Loss: 0.10\n",
      "Epoch: 003/010 train acc: 100.000 % | val acc: 95.833 % | time: 2.649 s\n",
      "Epoch: 004/010 | Batch 000/019 | Loss: 0.31\n",
      "Epoch: 004/010 | Batch 001/019 | Loss: 0.03\n",
      "Epoch: 004/010 | Batch 002/019 | Loss: 0.02\n",
      "Epoch: 004/010 | Batch 003/019 | Loss: 0.01\n",
      "Epoch: 004/010 | Batch 004/019 | Loss: 0.01\n",
      "Epoch: 004/010 | Batch 005/019 | Loss: 0.02\n",
      "Epoch: 004/010 | Batch 006/019 | Loss: 0.03\n",
      "Epoch: 004/010 | Batch 007/019 | Loss: 0.13\n",
      "Epoch: 004/010 | Batch 008/019 | Loss: 0.02\n",
      "Epoch: 004/010 | Batch 009/019 | Loss: 0.02\n",
      "Epoch: 004/010 | Batch 010/019 | Loss: 0.05\n",
      "Epoch: 004/010 | Batch 011/019 | Loss: 0.01\n",
      "Epoch: 004/010 | Batch 012/019 | Loss: 0.05\n",
      "Epoch: 004/010 | Batch 013/019 | Loss: 0.28\n",
      "Epoch: 004/010 | Batch 014/019 | Loss: 0.84\n",
      "Epoch: 004/010 | Batch 015/019 | Loss: 0.29\n",
      "Epoch: 004/010 | Batch 016/019 | Loss: 0.03\n",
      "Epoch: 004/010 | Batch 017/019 | Loss: 2.55\n",
      "Epoch: 004/010 | Batch 018/019 | Loss: 0.14\n",
      "Epoch: 004/010 | Batch 019/019 | Loss: 2.02\n",
      "Epoch: 004/010 train acc: 98.958 % | val acc: 95.833 % | time: 2.663 s\n",
      "Epoch: 005/010 | Batch 000/019 | Loss: 0.08\n",
      "Epoch: 005/010 | Batch 001/019 | Loss: 0.07\n",
      "Epoch: 005/010 | Batch 002/019 | Loss: 0.72\n",
      "Epoch: 005/010 | Batch 003/019 | Loss: 0.12\n",
      "Epoch: 005/010 | Batch 004/019 | Loss: 0.06\n",
      "Epoch: 005/010 | Batch 005/019 | Loss: 0.04\n",
      "Epoch: 005/010 | Batch 006/019 | Loss: 0.08\n",
      "Epoch: 005/010 | Batch 007/019 | Loss: 0.06\n",
      "Epoch: 005/010 | Batch 008/019 | Loss: 0.06\n",
      "Epoch: 005/010 | Batch 009/019 | Loss: 0.06\n",
      "Epoch: 005/010 | Batch 010/019 | Loss: 0.11\n",
      "Epoch: 005/010 | Batch 011/019 | Loss: 0.07\n",
      "Epoch: 005/010 | Batch 012/019 | Loss: 0.10\n",
      "Epoch: 005/010 | Batch 013/019 | Loss: 0.04\n",
      "Epoch: 005/010 | Batch 014/019 | Loss: 0.04\n",
      "Epoch: 005/010 | Batch 015/019 | Loss: 0.42\n",
      "Epoch: 005/010 | Batch 016/019 | Loss: 0.04\n",
      "Epoch: 005/010 | Batch 017/019 | Loss: 0.25\n",
      "Epoch: 005/010 | Batch 018/019 | Loss: 0.02\n",
      "Epoch: 005/010 | Batch 019/019 | Loss: 0.16\n",
      "Epoch: 005/010 train acc: 96.875 % | val acc: 95.833 % | time: 2.647 s\n",
      "Epoch: 006/010 | Batch 000/019 | Loss: 0.10\n",
      "Epoch: 006/010 | Batch 001/019 | Loss: 0.04\n",
      "Epoch: 006/010 | Batch 002/019 | Loss: 0.04\n",
      "Epoch: 006/010 | Batch 003/019 | Loss: 0.18\n",
      "Epoch: 006/010 | Batch 004/019 | Loss: 0.15\n",
      "Epoch: 006/010 | Batch 005/019 | Loss: 0.24\n",
      "Epoch: 006/010 | Batch 006/019 | Loss: 0.10\n",
      "Epoch: 006/010 | Batch 007/019 | Loss: 0.06\n",
      "Epoch: 006/010 | Batch 008/019 | Loss: 0.01\n",
      "Epoch: 006/010 | Batch 009/019 | Loss: 0.05\n",
      "Epoch: 006/010 | Batch 010/019 | Loss: 0.01\n",
      "Epoch: 006/010 | Batch 011/019 | Loss: 0.02\n",
      "Epoch: 006/010 | Batch 012/019 | Loss: 0.01\n",
      "Epoch: 006/010 | Batch 013/019 | Loss: 0.04\n",
      "Epoch: 006/010 | Batch 014/019 | Loss: 0.01\n",
      "Epoch: 006/010 | Batch 015/019 | Loss: 0.10\n",
      "Epoch: 006/010 | Batch 016/019 | Loss: 0.03\n",
      "Epoch: 006/010 | Batch 017/019 | Loss: 0.26\n",
      "Epoch: 006/010 | Batch 018/019 | Loss: 0.02\n",
      "Epoch: 006/010 | Batch 019/019 | Loss: 1.42\n",
      "Epoch: 006/010 train acc: 100.000 % | val acc: 95.833 % | time: 2.675 s\n",
      "Epoch: 007/010 | Batch 000/019 | Loss: 0.01\n",
      "Epoch: 007/010 | Batch 001/019 | Loss: 0.02\n",
      "Epoch: 007/010 | Batch 002/019 | Loss: 0.19\n",
      "Epoch: 007/010 | Batch 003/019 | Loss: 0.23\n",
      "Epoch: 007/010 | Batch 004/019 | Loss: 0.02\n",
      "Epoch: 007/010 | Batch 005/019 | Loss: 0.07\n",
      "Epoch: 007/010 | Batch 006/019 | Loss: 0.04\n",
      "Epoch: 007/010 | Batch 007/019 | Loss: 0.07\n",
      "Epoch: 007/010 | Batch 008/019 | Loss: 0.05\n",
      "Epoch: 007/010 | Batch 009/019 | Loss: 0.03\n",
      "Epoch: 007/010 | Batch 010/019 | Loss: 0.05\n",
      "Epoch: 007/010 | Batch 011/019 | Loss: 0.02\n",
      "Epoch: 007/010 | Batch 012/019 | Loss: 0.02\n",
      "Epoch: 007/010 | Batch 013/019 | Loss: 0.33\n",
      "Epoch: 007/010 | Batch 014/019 | Loss: 0.04\n",
      "Epoch: 007/010 | Batch 015/019 | Loss: 0.03\n",
      "Epoch: 007/010 | Batch 016/019 | Loss: 0.02\n",
      "Epoch: 007/010 | Batch 017/019 | Loss: 0.01\n",
      "Epoch: 007/010 | Batch 018/019 | Loss: 0.04\n",
      "Epoch: 007/010 | Batch 019/019 | Loss: 1.28\n",
      "Epoch: 007/010 train acc: 100.000 % | val acc: 95.833 % | time: 2.677 s\n",
      "Epoch: 008/010 | Batch 000/019 | Loss: 0.02\n",
      "Epoch: 008/010 | Batch 001/019 | Loss: 0.01\n",
      "Epoch: 008/010 | Batch 002/019 | Loss: 0.02\n",
      "Epoch: 008/010 | Batch 003/019 | Loss: 0.01\n",
      "Epoch: 008/010 | Batch 004/019 | Loss: 0.26\n",
      "Epoch: 008/010 | Batch 005/019 | Loss: 0.01\n",
      "Epoch: 008/010 | Batch 006/019 | Loss: 0.01\n",
      "Epoch: 008/010 | Batch 007/019 | Loss: 0.01\n",
      "Epoch: 008/010 | Batch 008/019 | Loss: 0.01\n",
      "Epoch: 008/010 | Batch 009/019 | Loss: 0.01\n",
      "Epoch: 008/010 | Batch 010/019 | Loss: 0.03\n",
      "Epoch: 008/010 | Batch 011/019 | Loss: 0.02\n",
      "Epoch: 008/010 | Batch 012/019 | Loss: 0.02\n",
      "Epoch: 008/010 | Batch 013/019 | Loss: 0.02\n",
      "Epoch: 008/010 | Batch 014/019 | Loss: 0.02\n",
      "Epoch: 008/010 | Batch 015/019 | Loss: 0.02\n",
      "Epoch: 008/010 | Batch 016/019 | Loss: 0.21\n",
      "Epoch: 008/010 | Batch 017/019 | Loss: 0.02\n",
      "Epoch: 008/010 | Batch 018/019 | Loss: 0.08\n",
      "Epoch: 008/010 | Batch 019/019 | Loss: 0.15\n",
      "Epoch: 008/010 train acc: 100.000 % | val acc: 95.833 % | time: 2.651 s\n",
      "Epoch: 009/010 | Batch 000/019 | Loss: 0.07\n",
      "Epoch: 009/010 | Batch 001/019 | Loss: 0.01\n",
      "Epoch: 009/010 | Batch 002/019 | Loss: 0.02\n",
      "Epoch: 009/010 | Batch 003/019 | Loss: 0.02\n",
      "Epoch: 009/010 | Batch 004/019 | Loss: 0.02\n",
      "Epoch: 009/010 | Batch 005/019 | Loss: 0.10\n",
      "Epoch: 009/010 | Batch 006/019 | Loss: 0.15\n",
      "Epoch: 009/010 | Batch 007/019 | Loss: 0.00\n",
      "Epoch: 009/010 | Batch 008/019 | Loss: 0.16\n",
      "Epoch: 009/010 | Batch 009/019 | Loss: 0.00\n",
      "Epoch: 009/010 | Batch 010/019 | Loss: 0.01\n",
      "Epoch: 009/010 | Batch 011/019 | Loss: 0.20\n",
      "Epoch: 009/010 | Batch 012/019 | Loss: 0.01\n",
      "Epoch: 009/010 | Batch 013/019 | Loss: 0.43\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 009/010 | Batch 014/019 | Loss: 0.06\n",
      "Epoch: 009/010 | Batch 015/019 | Loss: 0.00\n",
      "Epoch: 009/010 | Batch 016/019 | Loss: 0.02\n",
      "Epoch: 009/010 | Batch 017/019 | Loss: 0.28\n",
      "Epoch: 009/010 | Batch 018/019 | Loss: 0.17\n",
      "Epoch: 009/010 | Batch 019/019 | Loss: 0.08\n",
      "Epoch: 009/010 train acc: 100.000 % | val acc: 95.833 % | time: 2.662 s\n",
      "Epoch: 010/010 | Batch 000/019 | Loss: 0.04\n",
      "Epoch: 010/010 | Batch 001/019 | Loss: 0.11\n",
      "Epoch: 010/010 | Batch 002/019 | Loss: 0.03\n",
      "Epoch: 010/010 | Batch 003/019 | Loss: 0.01\n",
      "Epoch: 010/010 | Batch 004/019 | Loss: 0.01\n",
      "Epoch: 010/010 | Batch 005/019 | Loss: 0.01\n",
      "Epoch: 010/010 | Batch 006/019 | Loss: 0.01\n",
      "Epoch: 010/010 | Batch 007/019 | Loss: 0.02\n",
      "Epoch: 010/010 | Batch 008/019 | Loss: 0.01\n",
      "Epoch: 010/010 | Batch 009/019 | Loss: 0.01\n",
      "Epoch: 010/010 | Batch 010/019 | Loss: 0.02\n",
      "Epoch: 010/010 | Batch 011/019 | Loss: 0.08\n",
      "Epoch: 010/010 | Batch 012/019 | Loss: 0.11\n",
      "Epoch: 010/010 | Batch 013/019 | Loss: 0.01\n",
      "Epoch: 010/010 | Batch 014/019 | Loss: 0.01\n",
      "Epoch: 010/010 | Batch 015/019 | Loss: 0.01\n",
      "Epoch: 010/010 | Batch 016/019 | Loss: 0.01\n",
      "Epoch: 010/010 | Batch 017/019 | Loss: 0.01\n",
      "Epoch: 010/010 | Batch 018/019 | Loss: 0.02\n",
      "Epoch: 010/010 | Batch 019/019 | Loss: 0.06\n",
      "Epoch: 010/010 train acc: 100.000 % | val acc: 100.000 % | time: 2.665 s\n"
     ]
    }
   ],
   "source": [
    "model, loss_list, train_acc_list, valid_acc_list = train_model(model, \n",
    "            dataset_loader, \n",
    "            optimizer, \n",
    "            NUM_EPOCHS, \n",
    "            device = DEVICE, \n",
    "            batch_size = BATCH_SIZE,\n",
    "            metric_func = compute_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_list, label='Minibatch cost')\n",
    "plt.plot(np.convolve(loss_list, \n",
    "                     np.ones(5,)/5, mode='valid'), \n",
    "         label='Running average')\n",
    "\n",
    "plt.ylabel('Cross Entropy')\n",
    "plt.xlabel('Iteration')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.arange(1, NUM_EPOCHS+1), train_acc_list, label='Training')\n",
    "plt.plot(np.arange(1, NUM_EPOCHS+1), valid_acc_list, label='Validation')\n",
    "\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test ACC: 100.00%\n"
     ]
    }
   ],
   "source": [
    "with torch.set_grad_enabled(False):\n",
    "    test_acc = compute_accuracy(model=model,\n",
    "                           data_loader=dataset_loader[\"test\"],\n",
    "                           device=DEVICE)\n",
    "\n",
    "print(f'Test ACC: {test_acc:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tryit",
   "language": "python",
   "name": "tryit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
