{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGG16 CIFAR-10 Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook implements the classic AlexNet convolutional network [1] and applies it to the CIFAR10 object classification dataset. The basic architecture is shown in the figure below:\n",
    "\n",
    "![](./images/vgg16/vgg16-arch.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The input to cov1 layer is of fixed size 224 x 224 RGB image. The image is passed through a stack of convolutional (conv.) layers, where the filters were used with a very small receptive field: 3×3 (which is the smallest size to capture the notion of left/right, up/down, center). In one of the configurations, it also utilizes 1×1 convolution filters, which can be seen as a linear transformation of the input channels (followed by non-linearity). The convolution stride is fixed to 1 pixel; the spatial padding of conv. layer input is such that the spatial resolution is preserved after convolution, i.e. the padding is 1-pixel for 3×3 conv. layers. Spatial pooling is carried out by five max-pooling layers, which follow some of the conv.  layers (not all the conv. layers are followed by max-pooling). Max-pooling is performed over a 2×2 pixel window, with stride 2.\n",
    "\n",
    "Three Fully-Connected (FC) layers follow a stack of convolutional layers (which has a different depth in different architectures): the first two have 4096 channels each, the third performs 1000-way ILSVRC classification and thus contains 1000 channels (one for each class). The final layer is the soft-max layer. The configuration of the fully connected layers is the same in all networks.\n",
    "\n",
    "All hidden layers are equipped with the rectification (ReLU) non-linearity. It is also noted that none of the networks (except for one) contain Local Response Normalisation (LRN), such normalization does not improve the performance on the ILSVRC dataset, but leads to increased memory consumption and computation time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/ZRC/miniconda3/envs/tryit/lib/python36.zip',\n",
       " '/Users/ZRC/miniconda3/envs/tryit/lib/python3.6',\n",
       " '/Users/ZRC/miniconda3/envs/tryit/lib/python3.6/lib-dynload',\n",
       " '',\n",
       " '/Users/ZRC/miniconda3/envs/tryit/lib/python3.6/site-packages',\n",
       " '/Users/ZRC/miniconda3/envs/tryit/lib/python3.6/site-packages/IPython/extensions',\n",
       " '/Users/ZRC/.ipython',\n",
       " '/Users/ZRC',\n",
       " '/Users/ZRC']"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"/Users/ZRC\")\n",
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import RandomSampler\n",
    "\n",
    "\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.utils import mem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPUMemory(total=0, free=0, used=0)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mem.gpu_mem_get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from coke.visualization.image import show_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "NUM_EPOCHS = 3\n",
    "LEARNING_RATE = 0.001\n",
    "RANDOM_SEED = 7\n",
    "\n",
    "# Architecture\n",
    "NUM_CLASSES = 10\n",
    "GRAYSCALE = False\n",
    "\n",
    "# other\n",
    "DEVICE = torch.device(\"cuda: 0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = {\"train\": transforms.Compose([\n",
    "                            transforms.Resize((224,224)),\n",
    "                            transforms.ToTensor()]),\n",
    "                    \"val\": transforms.Compose([\n",
    "                      transforms.Resize((224,224)),\n",
    "                      transforms.ToTensor()])\n",
    "                   }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_dataset = datasets.CIFAR10(root = \"data\",\n",
    "                                train = True,\n",
    "                                transform = data_transforms[\"train\"],\n",
    "                                download=True)\n",
    "\n",
    "test_dataset = datasets.CIFAR10(root = \"data\",\n",
    "                                train = False,\n",
    "                                transform = data_transforms[\"val\"],\n",
    "                                download=False)\n",
    "\n",
    "train_dataloader = DataLoader(dataset = train_dataset,\n",
    "                             batch_size=BATCH_SIZE,\n",
    "                             shuffle=True,\n",
    "                             num_workers=4)\n",
    "\n",
    "test_dataloader = DataLoader(dataset = test_dataset,\n",
    "                             batch_size=BATCH_SIZE,\n",
    "                             shuffle=False,\n",
    "                             num_workers=4)\n",
    "\n",
    "data_loader = {\"train\": train_dataloader, \"val\": test_dataloader}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 3, 224, 224]), torch.Size([32]))"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_samples,labels = next(iter(train_dataloader))\n",
    "batch_samples.shape,labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(show_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_batch(batch_samples.permute(0,2,3,1), labels.numpy(), (4,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vgg16Zrc(torch.nn.Module):\n",
    "    def __init__(self, num_classes, grascale = False):\n",
    "        super(Vgg16Zrc, self).__init__()\n",
    "        if grascale:\n",
    "            in_channels = 1\n",
    "        else:\n",
    "            in_channels = 3\n",
    "            \n",
    "        #[3*224*224] -> [64*224*224]\n",
    "        self.block_1 = torch.nn.Sequential(\n",
    "        \n",
    "            torch.nn.Conv2d(in_channels = in_channels, \n",
    "                            out_channels = 64,\n",
    "                            kernel_size = 3,\n",
    "                            stride = 1,\n",
    "                            padding = 1),\n",
    "            torch.nn.BatchNorm2d(64),\n",
    "            torch.nn.ReLU(inplace = True),\n",
    "            torch.nn.Dropout(0.5),\n",
    "            \n",
    "            torch.nn.Conv2d(64, \n",
    "                            out_channels = 64,\n",
    "                            kernel_size = 3,\n",
    "                            stride = 1,\n",
    "                            padding = 1),\n",
    "            torch.nn.BatchNorm2d(64),\n",
    "            torch.nn.ReLU(inplace = True),\n",
    "            torch.nn.Dropout(0.5),\n",
    "        )\n",
    "        \n",
    "        \n",
    "        #[64*224*224] -> [128*112*112]\n",
    "        self.block_2 = torch.nn.Sequential(\n",
    "            torch.nn.MaxPool2d(kernel_size = 2,\n",
    "                              stride = 2),\n",
    "            torch.nn.Conv2d(in_channels = 64, \n",
    "                            out_channels = 128,\n",
    "                            kernel_size = 3,\n",
    "                            stride = 1,\n",
    "                            padding = 1),\n",
    "            torch.nn.BatchNorm2d(128),\n",
    "            torch.nn.ReLU(inplace = True),\n",
    "            torch.nn.Dropout(0.5),\n",
    "            \n",
    "            torch.nn.Conv2d(128, \n",
    "                            out_channels = 128,\n",
    "                            kernel_size = 3,\n",
    "                            stride = 1,\n",
    "                            padding = 1),\n",
    "            torch.nn.BatchNorm2d(128),\n",
    "            torch.nn.ReLU(inplace = True),\n",
    "            torch.nn.Dropout(0.5),\n",
    "        )\n",
    "        \n",
    "        # [128*112*112] -> [256*56*56]\n",
    "        self.block_3 = self.__block_helper(128,256)\n",
    "        # [256*56*56] -> [512*28*28]\n",
    "        self.block_4 = self.__block_helper(256,512)\n",
    "        # [512*28*28] -> [512*14*14]\n",
    "        self.block_5 = self.__block_helper(512,512)\n",
    "        \n",
    "        \n",
    "        self.classifier = torch.nn.Sequential(\n",
    "            # [512*14*14] -> [512*7*7]\n",
    "            torch.nn.MaxPool2d(kernel_size = 2,\n",
    "                              stride = 2),\n",
    "#             torch.nn.AdaptiveAvgPool2d((7,7)),\n",
    "            torch.nn.AdaptiveAvgPool2d(1),\n",
    "            torch.nn.Flatten(),\n",
    "            \n",
    "            # [512*7*7] -> [4096]\n",
    "            torch.nn.Linear(in_features = 512, out_features = 4096),\n",
    "            torch.nn.BatchNorm1d(4096),\n",
    "            torch.nn.ReLU(inplace = True),\n",
    "            torch.nn.Dropout(0.5),\n",
    "            \n",
    "            # [4096] -> [4096]\n",
    "            torch.nn.Linear(in_features = 4096, out_features = 4096),\n",
    "            torch.nn.BatchNorm1d(4096),\n",
    "            torch.nn.ReLU(inplace = True),\n",
    "            torch.nn.Dropout(0.5),\n",
    "            \n",
    "            # [4096] -> [num_classes]\n",
    "            torch.nn.Linear(in_features = 4096, out_features = num_classes)\n",
    "        )\n",
    "        \n",
    "        self.layers = torch.nn.ModuleList([self.block_1,self.block_2,self.block_3,self.block_4,self.block_5])\n",
    "        \n",
    "        \n",
    "    def forward(self,x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        \n",
    "        logits = self.classifier(x)\n",
    "        probas = F.softmax(logits, dim=1)\n",
    "        return logits,probas\n",
    "    \n",
    "    \n",
    "    \n",
    "    def __block_helper(self,in_channels, out_channels):\n",
    "        return torch.nn.Sequential(\n",
    "            torch.nn.MaxPool2d(kernel_size = 2,\n",
    "                              stride = 2),\n",
    "            torch.nn.Conv2d(in_channels = in_channels, \n",
    "                            out_channels = out_channels,\n",
    "                            kernel_size = 3,\n",
    "                            stride = 1,\n",
    "                            padding = 1),\n",
    "            torch.nn.ReLU(inplace = True),\n",
    "            torch.nn.Dropout(),\n",
    "            \n",
    "            torch.nn.Conv2d(in_channels = out_channels, \n",
    "                            out_channels = out_channels,\n",
    "                            kernel_size = 3,\n",
    "                            stride = 1,\n",
    "                            padding = 1),\n",
    "            \n",
    "            torch.nn.ReLU(inplace = True),\n",
    "            torch.nn.Dropout(),\n",
    "            \n",
    "            torch.nn.Conv2d(in_channels= out_channels, \n",
    "                            out_channels = out_channels,\n",
    "                            kernel_size = 3,\n",
    "                            stride = 1,\n",
    "                            padding = 1),\n",
    "            torch.nn.ReLU(inplace = True),\n",
    "            torch.nn.Dropout()\n",
    "            \n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(layer):\n",
    "\n",
    "    if isinstance(layer, torch.nn.Conv2d):\n",
    "        torch.nn.init.kaiming_normal_(layer.weight, mode='fan_out', nonlinearity='relu')\n",
    "        if layer.bias is not None:\n",
    "            torch.nn.init.constant_(layer.bias, 0)\n",
    "    elif isinstance(layer, torch.nn.BatchNorm2d):\n",
    "        torch.nn.init.constant_(layer.weight, 1)\n",
    "        torch.nn.init.constant_(layer.bias, 0)\n",
    "    elif isinstance(layer, torch.nn.Linear):\n",
    "        torch.nn.init.normal_(layer.weight, 0, 0.01)\n",
    "        torch.nn.init.constant_(layer.bias, 0)\n",
    "\n",
    "            \n",
    "model = Vgg16Zrc(num_classes = NUM_CLASSES)\n",
    "model.apply(init_weights)\n",
    "model = model.to(DEVICE)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 224, 224]           1,792\n",
      "            Conv2d-2         [-1, 64, 224, 224]           1,792\n",
      "       BatchNorm2d-3         [-1, 64, 224, 224]             128\n",
      "       BatchNorm2d-4         [-1, 64, 224, 224]             128\n",
      "              ReLU-5         [-1, 64, 224, 224]               0\n",
      "              ReLU-6         [-1, 64, 224, 224]               0\n",
      "           Dropout-7         [-1, 64, 224, 224]               0\n",
      "           Dropout-8         [-1, 64, 224, 224]               0\n",
      "            Conv2d-9         [-1, 64, 224, 224]          36,928\n",
      "           Conv2d-10         [-1, 64, 224, 224]          36,928\n",
      "      BatchNorm2d-11         [-1, 64, 224, 224]             128\n",
      "      BatchNorm2d-12         [-1, 64, 224, 224]             128\n",
      "             ReLU-13         [-1, 64, 224, 224]               0\n",
      "             ReLU-14         [-1, 64, 224, 224]               0\n",
      "          Dropout-15         [-1, 64, 224, 224]               0\n",
      "          Dropout-16         [-1, 64, 224, 224]               0\n",
      "        MaxPool2d-17         [-1, 64, 112, 112]               0\n",
      "        MaxPool2d-18         [-1, 64, 112, 112]               0\n",
      "           Conv2d-19        [-1, 128, 112, 112]          73,856\n",
      "           Conv2d-20        [-1, 128, 112, 112]          73,856\n",
      "      BatchNorm2d-21        [-1, 128, 112, 112]             256\n",
      "      BatchNorm2d-22        [-1, 128, 112, 112]             256\n",
      "             ReLU-23        [-1, 128, 112, 112]               0\n",
      "             ReLU-24        [-1, 128, 112, 112]               0\n",
      "          Dropout-25        [-1, 128, 112, 112]               0\n",
      "          Dropout-26        [-1, 128, 112, 112]               0\n",
      "           Conv2d-27        [-1, 128, 112, 112]         147,584\n",
      "           Conv2d-28        [-1, 128, 112, 112]         147,584\n",
      "      BatchNorm2d-29        [-1, 128, 112, 112]             256\n",
      "      BatchNorm2d-30        [-1, 128, 112, 112]             256\n",
      "             ReLU-31        [-1, 128, 112, 112]               0\n",
      "             ReLU-32        [-1, 128, 112, 112]               0\n",
      "          Dropout-33        [-1, 128, 112, 112]               0\n",
      "          Dropout-34        [-1, 128, 112, 112]               0\n",
      "        MaxPool2d-35          [-1, 128, 56, 56]               0\n",
      "        MaxPool2d-36          [-1, 128, 56, 56]               0\n",
      "           Conv2d-37          [-1, 256, 56, 56]         295,168\n",
      "           Conv2d-38          [-1, 256, 56, 56]         295,168\n",
      "             ReLU-39          [-1, 256, 56, 56]               0\n",
      "             ReLU-40          [-1, 256, 56, 56]               0\n",
      "          Dropout-41          [-1, 256, 56, 56]               0\n",
      "          Dropout-42          [-1, 256, 56, 56]               0\n",
      "           Conv2d-43          [-1, 256, 56, 56]         590,080\n",
      "           Conv2d-44          [-1, 256, 56, 56]         590,080\n",
      "             ReLU-45          [-1, 256, 56, 56]               0\n",
      "             ReLU-46          [-1, 256, 56, 56]               0\n",
      "          Dropout-47          [-1, 256, 56, 56]               0\n",
      "          Dropout-48          [-1, 256, 56, 56]               0\n",
      "           Conv2d-49          [-1, 256, 56, 56]         590,080\n",
      "           Conv2d-50          [-1, 256, 56, 56]         590,080\n",
      "             ReLU-51          [-1, 256, 56, 56]               0\n",
      "             ReLU-52          [-1, 256, 56, 56]               0\n",
      "          Dropout-53          [-1, 256, 56, 56]               0\n",
      "          Dropout-54          [-1, 256, 56, 56]               0\n",
      "        MaxPool2d-55          [-1, 256, 28, 28]               0\n",
      "        MaxPool2d-56          [-1, 256, 28, 28]               0\n",
      "           Conv2d-57          [-1, 512, 28, 28]       1,180,160\n",
      "           Conv2d-58          [-1, 512, 28, 28]       1,180,160\n",
      "             ReLU-59          [-1, 512, 28, 28]               0\n",
      "             ReLU-60          [-1, 512, 28, 28]               0\n",
      "          Dropout-61          [-1, 512, 28, 28]               0\n",
      "          Dropout-62          [-1, 512, 28, 28]               0\n",
      "           Conv2d-63          [-1, 512, 28, 28]       2,359,808\n",
      "           Conv2d-64          [-1, 512, 28, 28]       2,359,808\n",
      "             ReLU-65          [-1, 512, 28, 28]               0\n",
      "             ReLU-66          [-1, 512, 28, 28]               0\n",
      "          Dropout-67          [-1, 512, 28, 28]               0\n",
      "          Dropout-68          [-1, 512, 28, 28]               0\n",
      "           Conv2d-69          [-1, 512, 28, 28]       2,359,808\n",
      "           Conv2d-70          [-1, 512, 28, 28]       2,359,808\n",
      "             ReLU-71          [-1, 512, 28, 28]               0\n",
      "             ReLU-72          [-1, 512, 28, 28]               0\n",
      "          Dropout-73          [-1, 512, 28, 28]               0\n",
      "          Dropout-74          [-1, 512, 28, 28]               0\n",
      "        MaxPool2d-75          [-1, 512, 14, 14]               0\n",
      "        MaxPool2d-76          [-1, 512, 14, 14]               0\n",
      "           Conv2d-77          [-1, 512, 14, 14]       2,359,808\n",
      "           Conv2d-78          [-1, 512, 14, 14]       2,359,808\n",
      "             ReLU-79          [-1, 512, 14, 14]               0\n",
      "             ReLU-80          [-1, 512, 14, 14]               0\n",
      "          Dropout-81          [-1, 512, 14, 14]               0\n",
      "          Dropout-82          [-1, 512, 14, 14]               0\n",
      "           Conv2d-83          [-1, 512, 14, 14]       2,359,808\n",
      "           Conv2d-84          [-1, 512, 14, 14]       2,359,808\n",
      "             ReLU-85          [-1, 512, 14, 14]               0\n",
      "             ReLU-86          [-1, 512, 14, 14]               0\n",
      "          Dropout-87          [-1, 512, 14, 14]               0\n",
      "          Dropout-88          [-1, 512, 14, 14]               0\n",
      "           Conv2d-89          [-1, 512, 14, 14]       2,359,808\n",
      "           Conv2d-90          [-1, 512, 14, 14]       2,359,808\n",
      "             ReLU-91          [-1, 512, 14, 14]               0\n",
      "             ReLU-92          [-1, 512, 14, 14]               0\n",
      "          Dropout-93          [-1, 512, 14, 14]               0\n",
      "          Dropout-94          [-1, 512, 14, 14]               0\n",
      "        MaxPool2d-95            [-1, 512, 7, 7]               0\n",
      "AdaptiveAvgPool2d-96            [-1, 512, 1, 1]               0\n",
      "          Flatten-97                  [-1, 512]               0\n",
      "           Linear-98                 [-1, 4096]       2,101,248\n",
      "      BatchNorm1d-99                 [-1, 4096]           8,192\n",
      "            ReLU-100                 [-1, 4096]               0\n",
      "         Dropout-101                 [-1, 4096]               0\n",
      "          Linear-102                 [-1, 4096]      16,781,312\n",
      "     BatchNorm1d-103                 [-1, 4096]           8,192\n",
      "            ReLU-104                 [-1, 4096]               0\n",
      "         Dropout-105                 [-1, 4096]               0\n",
      "          Linear-106                   [-1, 10]          40,970\n",
      "================================================================\n",
      "Total params: 48,370,826\n",
      "Trainable params: 48,370,826\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 790.57\n",
      "Params size (MB): 184.52\n",
      "Estimated Total Size (MB): 975.67\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(model, (3,224,224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(model, data_loader, device):\n",
    "    model.eval()\n",
    "    correct_pred, num_examples = 0, 0\n",
    "    for i, (features, targets) in enumerate(data_loader):\n",
    "            \n",
    "        features = features.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        logits, probas = model(features)\n",
    "        _, predicted_labels = torch.max(probas, 1)\n",
    "        num_examples += targets.size(0)\n",
    "        correct_pred += (predicted_labels == targets).sum()\n",
    "    return correct_pred.float()/num_examples * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, data_loader, optimizer, num_epochs,batch_size, device,metric_func, random_seed = 7):\n",
    "    # Manual seed for deterministic data loader\n",
    "    torch.manual_seed(random_seed)\n",
    "    for epoch in range(num_epochs):\n",
    "        # set training mode\n",
    "        model.train() \n",
    "        for batch_idx, (features, targets) in enumerate(data_loader[\"train\"]):\n",
    "            features = features.to(device)\n",
    "            targets = targets.to(device)\n",
    "\n",
    "\n",
    "            ## forward pass\n",
    "            logits, probas = model(features)\n",
    "            loss = F.cross_entropy(logits,targets)\n",
    "\n",
    "            # backward pass\n",
    "            # clear the gradients of all tensors being optimized\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            ### Login\n",
    "            if not batch_idx % 50:\n",
    "                print ('Epoch: {0:03d}/{1:03d} | Batch {2:03d}/{3:03d} | Loss: {4:.2f}'.format(\n",
    "                    epoch+1, num_epochs, batch_idx, \n",
    "                         len(train_dataset)//batch_size, loss))\n",
    "\n",
    "        with torch.set_grad_enabled(False):\n",
    "            print('Epoch: {0:03d}/{1:03d} training accuracy: {2:.2f}'.format(\n",
    "                  epoch+1, num_epochs, \n",
    "                  metric_func(model, data_loader[\"train\"], device)))\n",
    "            \n",
    "            print('Epoch: {0:03d}/{1:03d} validation accuracy: {2:.2f}'.format(\n",
    "                  epoch+1, num_epochs, \n",
    "                  metric_func(model, data_loader[\"val\"], device)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model(model, \n",
    "            data_loader, \n",
    "            optimizer, \n",
    "            NUM_EPOCHS, \n",
    "            device = DEVICE, \n",
    "            batch_size = BATCH_SIZE,\n",
    "            metric_func = compute_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tryit",
   "language": "python",
   "name": "tryit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
