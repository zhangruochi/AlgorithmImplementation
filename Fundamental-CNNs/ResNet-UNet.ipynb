{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UNet/FCN Based on ResNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This repository contains simple PyTorch implementations of U-Net and FCN, which are deep learning segmentation methods proposed by Ronneberger et al. and Long et al."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet18-5c106cde.pth\" to /Users/ZRC/.cache/torch/checkpoints/resnet18-5c106cde.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b807e7491e834b0bb8019dceb037a10f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=46827520.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "base_model = models.resnet18(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 conv1  ->  Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "--------------------------------------------------------------------------------\n",
      "1 bn1  ->  BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "--------------------------------------------------------------------------------\n",
      "2 relu  ->  ReLU(inplace=True)\n",
      "--------------------------------------------------------------------------------\n",
      "3 maxpool  ->  MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "--------------------------------------------------------------------------------\n",
      "4 layer1  ->  Sequential(\n",
      "  (0): BasicBlock(\n",
      "    (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (1): BasicBlock(\n",
      "    (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      ")\n",
      "--------------------------------------------------------------------------------\n",
      "5 layer2  ->  Sequential(\n",
      "  (0): BasicBlock(\n",
      "    (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (downsample): Sequential(\n",
      "      (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (1): BasicBlock(\n",
      "    (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      ")\n",
      "--------------------------------------------------------------------------------\n",
      "6 layer3  ->  Sequential(\n",
      "  (0): BasicBlock(\n",
      "    (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (downsample): Sequential(\n",
      "      (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (1): BasicBlock(\n",
      "    (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      ")\n",
      "--------------------------------------------------------------------------------\n",
      "7 layer4  ->  Sequential(\n",
      "  (0): BasicBlock(\n",
      "    (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (downsample): Sequential(\n",
      "      (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (1): BasicBlock(\n",
      "    (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      ")\n",
      "--------------------------------------------------------------------------------\n",
      "8 avgpool  ->  AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "--------------------------------------------------------------------------------\n",
      "9 fc  ->  Linear(in_features=512, out_features=1000, bias=True)\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for index, (name, layer) in enumerate(base_model.named_children()):\n",
    "    print(index, name, \" -> \", layer)\n",
    "    print(\"--\"* 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference\n",
    "\n",
    "- https://github.com/usuyama/pytorch-unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(base_model.children()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models\n",
    "\n",
    "def convrelu(in_channels, out_channels, kernel, padding):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(in_channels, out_channels, kernel, padding=padding),\n",
    "        nn.ReLU(inplace=True),\n",
    "    )\n",
    "\n",
    "\n",
    "class ResNetUNetZrc(nn.Module):\n",
    "    def __init__(self, n_class):\n",
    "        super().__init__()\n",
    "\n",
    "        self.base_model = models.resnet18(pretrained=True)\n",
    "        self.base_layers = list(self.base_model.children())\n",
    "\n",
    "        self.layer0 = nn.Sequential(*self.base_layers[:3]) # size=(N, 64, x.H/2, x.W/2)\n",
    "        self.layer0_1x1 = convrelu(64, 64, 1, 0)\n",
    "        self.layer1 = nn.Sequential(*self.base_layers[3:5]) # size=(N, 64, x.H/4, x.W/4)\n",
    "        self.layer1_1x1 = convrelu(64, 64, 1, 0)\n",
    "        self.layer2 = self.base_layers[5]  # size=(N, 128, x.H/8, x.W/8)\n",
    "        self.layer2_1x1 = convrelu(128, 128, 1, 0)\n",
    "        self.layer3 = self.base_layers[6]  # size=(N, 256, x.H/16, x.W/16)\n",
    "        self.layer3_1x1 = convrelu(256, 256, 1, 0)\n",
    "        self.layer4 = self.base_layers[7]  # size=(N, 512, x.H/32, x.W/32)\n",
    "        self.layer4_1x1 = convrelu(512, 512, 1, 0)\n",
    "\n",
    "        self.upsample = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "\n",
    "        self.conv_up3 = convrelu(256 + 512, 512, 3, 1)\n",
    "        self.conv_up2 = convrelu(128 + 512, 256, 3, 1)\n",
    "        self.conv_up1 = convrelu(64 + 256, 256, 3, 1)\n",
    "        self.conv_up0 = convrelu(64 + 256, 128, 3, 1)\n",
    "\n",
    "        self.conv_original_size0 = convrelu(3, 64, 3, 1)\n",
    "        self.conv_original_size1 = convrelu(64, 64, 3, 1)\n",
    "        self.conv_original_size2 = convrelu(64 + 128, 64, 3, 1)\n",
    "\n",
    "        self.conv_last = nn.Conv2d(64, n_class, 1)\n",
    "\n",
    "    def forward(self, input):\n",
    "        x_original = self.conv_original_size0(input)\n",
    "        x_original = self.conv_original_size1(x_original)  # 64\n",
    "\n",
    "        layer0 = self.layer0(input)    # 64  /2\n",
    "        layer1 = self.layer1(layer0)#  # 64  /4\n",
    "        layer2 = self.layer2(layer1)   # 128 /8  \n",
    "        layer3 = self.layer3(layer2)   # 256 /16 \n",
    "        layer4 = self.layer4(layer3)   # 512 /32\n",
    "\n",
    "        layer4 = self.layer4_1x1(layer4)\n",
    "        x = self.upsample(layer4)      # 512 / 16\n",
    "        layer3 = self.layer3_1x1(layer3) # 256 / 16\n",
    "        x = torch.cat([x, layer3], dim=1) # 256 + 512 / 16\n",
    "        x = self.conv_up3(x)       # 512   /16\n",
    "\n",
    "        x = self.upsample(x)       # 512   /8\n",
    "        layer2 = self.layer2_1x1(layer2) #  128  /8\n",
    "        x = torch.cat([x, layer2], dim=1) # 512 + 128 /8\n",
    "        x = self.conv_up2(x)    # 256 /8\n",
    "\n",
    "        x = self.upsample(x)    # 256 /4\n",
    "        layer1 = self.layer1_1x1(layer1)  # 64 / 4\n",
    "        x = torch.cat([x, layer1], dim=1) # 64 + 256 /4\n",
    "        x = self.conv_up1(x)   # 256  /4\n",
    "\n",
    "        x = self.upsample(x)\n",
    "        layer0 = self.layer0_1x1(layer0)\n",
    "        x = torch.cat([x, layer0], dim=1)\n",
    "        x = self.conv_up0(x)    # 128  /2\n",
    "\n",
    "        x = self.upsample(x)    # 128 \n",
    "        x = torch.cat([x, x_original], dim=1)  #  128 + 64\n",
    "        x = self.conv_original_size2(x)    \n",
    "\n",
    "        out = self.conv_last(x)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 224, 224]           1,792\n",
      "              ReLU-2         [-1, 64, 224, 224]               0\n",
      "            Conv2d-3         [-1, 64, 224, 224]          36,928\n",
      "              ReLU-4         [-1, 64, 224, 224]               0\n",
      "            Conv2d-5         [-1, 64, 112, 112]           9,408\n",
      "            Conv2d-6         [-1, 64, 112, 112]           9,408\n",
      "       BatchNorm2d-7         [-1, 64, 112, 112]             128\n",
      "       BatchNorm2d-8         [-1, 64, 112, 112]             128\n",
      "              ReLU-9         [-1, 64, 112, 112]               0\n",
      "             ReLU-10         [-1, 64, 112, 112]               0\n",
      "        MaxPool2d-11           [-1, 64, 56, 56]               0\n",
      "        MaxPool2d-12           [-1, 64, 56, 56]               0\n",
      "           Conv2d-13           [-1, 64, 56, 56]          36,864\n",
      "           Conv2d-14           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-15           [-1, 64, 56, 56]             128\n",
      "      BatchNorm2d-16           [-1, 64, 56, 56]             128\n",
      "             ReLU-17           [-1, 64, 56, 56]               0\n",
      "             ReLU-18           [-1, 64, 56, 56]               0\n",
      "           Conv2d-19           [-1, 64, 56, 56]          36,864\n",
      "           Conv2d-20           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-21           [-1, 64, 56, 56]             128\n",
      "      BatchNorm2d-22           [-1, 64, 56, 56]             128\n",
      "             ReLU-23           [-1, 64, 56, 56]               0\n",
      "             ReLU-24           [-1, 64, 56, 56]               0\n",
      "       BasicBlock-25           [-1, 64, 56, 56]               0\n",
      "       BasicBlock-26           [-1, 64, 56, 56]               0\n",
      "           Conv2d-27           [-1, 64, 56, 56]          36,864\n",
      "           Conv2d-28           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-29           [-1, 64, 56, 56]             128\n",
      "      BatchNorm2d-30           [-1, 64, 56, 56]             128\n",
      "             ReLU-31           [-1, 64, 56, 56]               0\n",
      "             ReLU-32           [-1, 64, 56, 56]               0\n",
      "           Conv2d-33           [-1, 64, 56, 56]          36,864\n",
      "           Conv2d-34           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-35           [-1, 64, 56, 56]             128\n",
      "      BatchNorm2d-36           [-1, 64, 56, 56]             128\n",
      "             ReLU-37           [-1, 64, 56, 56]               0\n",
      "             ReLU-38           [-1, 64, 56, 56]               0\n",
      "       BasicBlock-39           [-1, 64, 56, 56]               0\n",
      "       BasicBlock-40           [-1, 64, 56, 56]               0\n",
      "           Conv2d-41          [-1, 128, 28, 28]          73,728\n",
      "           Conv2d-42          [-1, 128, 28, 28]          73,728\n",
      "      BatchNorm2d-43          [-1, 128, 28, 28]             256\n",
      "      BatchNorm2d-44          [-1, 128, 28, 28]             256\n",
      "             ReLU-45          [-1, 128, 28, 28]               0\n",
      "             ReLU-46          [-1, 128, 28, 28]               0\n",
      "           Conv2d-47          [-1, 128, 28, 28]         147,456\n",
      "           Conv2d-48          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-49          [-1, 128, 28, 28]             256\n",
      "      BatchNorm2d-50          [-1, 128, 28, 28]             256\n",
      "           Conv2d-51          [-1, 128, 28, 28]           8,192\n",
      "           Conv2d-52          [-1, 128, 28, 28]           8,192\n",
      "      BatchNorm2d-53          [-1, 128, 28, 28]             256\n",
      "      BatchNorm2d-54          [-1, 128, 28, 28]             256\n",
      "             ReLU-55          [-1, 128, 28, 28]               0\n",
      "             ReLU-56          [-1, 128, 28, 28]               0\n",
      "       BasicBlock-57          [-1, 128, 28, 28]               0\n",
      "       BasicBlock-58          [-1, 128, 28, 28]               0\n",
      "           Conv2d-59          [-1, 128, 28, 28]         147,456\n",
      "           Conv2d-60          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-61          [-1, 128, 28, 28]             256\n",
      "      BatchNorm2d-62          [-1, 128, 28, 28]             256\n",
      "             ReLU-63          [-1, 128, 28, 28]               0\n",
      "             ReLU-64          [-1, 128, 28, 28]               0\n",
      "           Conv2d-65          [-1, 128, 28, 28]         147,456\n",
      "           Conv2d-66          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-67          [-1, 128, 28, 28]             256\n",
      "      BatchNorm2d-68          [-1, 128, 28, 28]             256\n",
      "             ReLU-69          [-1, 128, 28, 28]               0\n",
      "             ReLU-70          [-1, 128, 28, 28]               0\n",
      "       BasicBlock-71          [-1, 128, 28, 28]               0\n",
      "       BasicBlock-72          [-1, 128, 28, 28]               0\n",
      "           Conv2d-73          [-1, 256, 14, 14]         294,912\n",
      "           Conv2d-74          [-1, 256, 14, 14]         294,912\n",
      "      BatchNorm2d-75          [-1, 256, 14, 14]             512\n",
      "      BatchNorm2d-76          [-1, 256, 14, 14]             512\n",
      "             ReLU-77          [-1, 256, 14, 14]               0\n",
      "             ReLU-78          [-1, 256, 14, 14]               0\n",
      "           Conv2d-79          [-1, 256, 14, 14]         589,824\n",
      "           Conv2d-80          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-81          [-1, 256, 14, 14]             512\n",
      "      BatchNorm2d-82          [-1, 256, 14, 14]             512\n",
      "           Conv2d-83          [-1, 256, 14, 14]          32,768\n",
      "           Conv2d-84          [-1, 256, 14, 14]          32,768\n",
      "      BatchNorm2d-85          [-1, 256, 14, 14]             512\n",
      "      BatchNorm2d-86          [-1, 256, 14, 14]             512\n",
      "             ReLU-87          [-1, 256, 14, 14]               0\n",
      "             ReLU-88          [-1, 256, 14, 14]               0\n",
      "       BasicBlock-89          [-1, 256, 14, 14]               0\n",
      "       BasicBlock-90          [-1, 256, 14, 14]               0\n",
      "           Conv2d-91          [-1, 256, 14, 14]         589,824\n",
      "           Conv2d-92          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-93          [-1, 256, 14, 14]             512\n",
      "      BatchNorm2d-94          [-1, 256, 14, 14]             512\n",
      "             ReLU-95          [-1, 256, 14, 14]               0\n",
      "             ReLU-96          [-1, 256, 14, 14]               0\n",
      "           Conv2d-97          [-1, 256, 14, 14]         589,824\n",
      "           Conv2d-98          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-99          [-1, 256, 14, 14]             512\n",
      "     BatchNorm2d-100          [-1, 256, 14, 14]             512\n",
      "            ReLU-101          [-1, 256, 14, 14]               0\n",
      "            ReLU-102          [-1, 256, 14, 14]               0\n",
      "      BasicBlock-103          [-1, 256, 14, 14]               0\n",
      "      BasicBlock-104          [-1, 256, 14, 14]               0\n",
      "          Conv2d-105            [-1, 512, 7, 7]       1,179,648\n",
      "          Conv2d-106            [-1, 512, 7, 7]       1,179,648\n",
      "     BatchNorm2d-107            [-1, 512, 7, 7]           1,024\n",
      "     BatchNorm2d-108            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-109            [-1, 512, 7, 7]               0\n",
      "            ReLU-110            [-1, 512, 7, 7]               0\n",
      "          Conv2d-111            [-1, 512, 7, 7]       2,359,296\n",
      "          Conv2d-112            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-113            [-1, 512, 7, 7]           1,024\n",
      "     BatchNorm2d-114            [-1, 512, 7, 7]           1,024\n",
      "          Conv2d-115            [-1, 512, 7, 7]         131,072\n",
      "          Conv2d-116            [-1, 512, 7, 7]         131,072\n",
      "     BatchNorm2d-117            [-1, 512, 7, 7]           1,024\n",
      "     BatchNorm2d-118            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-119            [-1, 512, 7, 7]               0\n",
      "            ReLU-120            [-1, 512, 7, 7]               0\n",
      "      BasicBlock-121            [-1, 512, 7, 7]               0\n",
      "      BasicBlock-122            [-1, 512, 7, 7]               0\n",
      "          Conv2d-123            [-1, 512, 7, 7]       2,359,296\n",
      "          Conv2d-124            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-125            [-1, 512, 7, 7]           1,024\n",
      "     BatchNorm2d-126            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-127            [-1, 512, 7, 7]               0\n",
      "            ReLU-128            [-1, 512, 7, 7]               0\n",
      "          Conv2d-129            [-1, 512, 7, 7]       2,359,296\n",
      "          Conv2d-130            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-131            [-1, 512, 7, 7]           1,024\n",
      "     BatchNorm2d-132            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-133            [-1, 512, 7, 7]               0\n",
      "            ReLU-134            [-1, 512, 7, 7]               0\n",
      "      BasicBlock-135            [-1, 512, 7, 7]               0\n",
      "      BasicBlock-136            [-1, 512, 7, 7]               0\n",
      "          Conv2d-137            [-1, 512, 7, 7]         262,656\n",
      "            ReLU-138            [-1, 512, 7, 7]               0\n",
      "        Upsample-139          [-1, 512, 14, 14]               0\n",
      "          Conv2d-140          [-1, 256, 14, 14]          65,792\n",
      "            ReLU-141          [-1, 256, 14, 14]               0\n",
      "          Conv2d-142          [-1, 512, 14, 14]       3,539,456\n",
      "            ReLU-143          [-1, 512, 14, 14]               0\n",
      "        Upsample-144          [-1, 512, 28, 28]               0\n",
      "          Conv2d-145          [-1, 128, 28, 28]          16,512\n",
      "            ReLU-146          [-1, 128, 28, 28]               0\n",
      "          Conv2d-147          [-1, 256, 28, 28]       1,474,816\n",
      "            ReLU-148          [-1, 256, 28, 28]               0\n",
      "        Upsample-149          [-1, 256, 56, 56]               0\n",
      "          Conv2d-150           [-1, 64, 56, 56]           4,160\n",
      "            ReLU-151           [-1, 64, 56, 56]               0\n",
      "          Conv2d-152          [-1, 256, 56, 56]         737,536\n",
      "            ReLU-153          [-1, 256, 56, 56]               0\n",
      "        Upsample-154        [-1, 256, 112, 112]               0\n",
      "          Conv2d-155         [-1, 64, 112, 112]           4,160\n",
      "            ReLU-156         [-1, 64, 112, 112]               0\n",
      "          Conv2d-157        [-1, 128, 112, 112]         368,768\n",
      "            ReLU-158        [-1, 128, 112, 112]               0\n",
      "        Upsample-159        [-1, 128, 224, 224]               0\n",
      "          Conv2d-160         [-1, 64, 224, 224]         110,656\n",
      "            ReLU-161         [-1, 64, 224, 224]               0\n",
      "          Conv2d-162         [-1, 10, 224, 224]             650\n",
      "================================================================\n",
      "Total params: 28,976,906\n",
      "Trainable params: 28,976,906\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 419.18\n",
      "Params size (MB): 110.54\n",
      "Estimated Total Size (MB): 530.29\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "model = ResNetUNetZrc(n_class = 10)\n",
    "summary(model, (3,224,224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tryit",
   "language": "python",
   "name": "tryit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
