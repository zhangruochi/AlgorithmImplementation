{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VISUALIZING MODELS, DATA, AND TRAINING WITH TENSORBOARD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to ./data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb77a6b154e3420a91b30318463b9d1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/FashionMNIST/raw/train-images-idx3-ubyte.gz to ./data/FashionMNIST/raw\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30afedb28dd24c1283e060cf7170a79c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to ./data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f105f99c63a4696b92cc457fadd29df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to ./data/FashionMNIST/raw\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee36aa7a100247ac96943aa971a28ffe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# transforms\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "# datasets\n",
    "trainset = torchvision.datasets.FashionMNIST('./data',\n",
    "    download=True,\n",
    "    train=True,\n",
    "    transform=transform)\n",
    "testset = torchvision.datasets.FashionMNIST('./data',\n",
    "    download=True,\n",
    "    train=False,\n",
    "    transform=transform)\n",
    "\n",
    "# dataloaders\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
    "                                        shuffle=True, num_workers=2)\n",
    "\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                        shuffle=False, num_workers=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constant for classes\n",
    "classes = ('T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "        'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle Boot')\n",
    "\n",
    "# helper function to show an image\n",
    "# (used in the `plot_classes_preds` function below)\n",
    "def matplotlib_imshow(img, one_channel=False):\n",
    "    if one_channel:\n",
    "        img = img.mean(dim=0)\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    if one_channel:\n",
    "        plt.imshow(npimg, cmap=\"Greys\")\n",
    "    else:\n",
    "        plt.imshow(np.transpose(npimg, (1, 2, 0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 4 * 4, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 4 * 4)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorBoard setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# default `log_dir` is \"runs\" - we'll be more specific here\n",
    "writer = SummaryWriter('runs/fashion_mnist_experiment_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# create grid of images\n",
    "img_grid = torchvision.utils.make_grid(images)\n",
    "\n",
    "# show images\n",
    "matplotlib_imshow(img_grid, one_channel=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write to tensorboard\n",
    "writer.add_image('four_fashion_mnist_images', img_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.add_graph(net, images)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions\n",
    "\n",
    "def images_to_probs(net, images):\n",
    "    '''\n",
    "    Generates predictions and corresponding probabilities from a trained\n",
    "    network and a list of images\n",
    "    '''\n",
    "    output = net(images)\n",
    "    # convert output probabilities to predicted class\n",
    "    _, preds_tensor = torch.max(output, 1)\n",
    "    preds = np.squeeze(preds_tensor.numpy())\n",
    "    return preds, [F.softmax(el, dim=0)[i].item() for i, el in zip(preds, output)]\n",
    "\n",
    "\n",
    "def plot_classes_preds(net, images, labels):\n",
    "    '''\n",
    "    Generates matplotlib Figure using a trained network, along with images\n",
    "    and labels from a batch, that shows the network's top prediction along\n",
    "    with its probability, alongside the actual label, coloring this\n",
    "    information based on whether the prediction was correct or not.\n",
    "    Uses the \"images_to_probs\" function.\n",
    "    '''\n",
    "    preds, probs = images_to_probs(net, images)\n",
    "    # plot the images in the batch, along with predicted and true labels\n",
    "    fig = plt.figure(figsize=(12, 48))\n",
    "    for idx in np.arange(4):\n",
    "        ax = fig.add_subplot(1, 4, idx+1, xticks=[], yticks=[])\n",
    "        matplotlib_imshow(images[idx], one_channel=True)\n",
    "        ax.set_title(\"{0}, {1:.1f}%\\n(label: {2})\".format(\n",
    "            classes[preds[idx]],\n",
    "            probs[idx] * 100.0,\n",
    "            classes[labels[idx]]),\n",
    "                    color=(\"green\" if preds[idx]==labels[idx].item() else \"red\"))\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "running_loss = 0.0\n",
    "for epoch in range(1):  # loop over the dataset multiple times\n",
    "\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if i % 1000 == 999:    # every 1000 mini-batches...\n",
    "\n",
    "            # ...log the running loss\n",
    "            writer.add_scalar('training loss',\n",
    "                            running_loss / 1000,\n",
    "                            epoch * len(trainloader) + i)\n",
    "\n",
    "            # ...log a Matplotlib Figure showing the model's predictions on a\n",
    "            # random mini-batch\n",
    "            writer.add_figure('predictions vs. actuals',\n",
    "                            plot_classes_preds(net, inputs, labels),\n",
    "                            global_step=epoch * len(trainloader) + i)\n",
    "            running_loss = 0.0\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tryit",
   "language": "python",
   "name": "tryit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
